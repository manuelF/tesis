
\subsection{Estructura inicial del programa}

El programa originalmente estaba concebido para ser corrido en GPU nVidia GTX8800.
Luego, las cosas que se usaron para este desarrollo consistieron en la libreria CUDA version
2, para arquitecturas a lo sumo SM20.

La estructura del programa era la siguiente:
\begin{enumerate}
\item Se determinan los mallados del sistema
\item Se clasifican en cubos y esferas
\item Para cada elemento, se resuelve el sistema
\item Esto se repite hasta que converga a lo sumo en una cantidad limitada de pasos, o diverga
\end{enumerate}

La resoluci\'on del sistema en si esta compuesta de varios pasos:
\begin{enumerate}
\item Se obtiene el valor de la funcion de onda en cada punto de la malla
\item Se generan las matrices con los gradientes y los hessianos de cada funcion
\item Se calculan las densidades y el producto matricial por bloques por funcion
\item Se obtienen las derivadas de la densidad calculada antes
\end{enumerate}


\subsection{Cuellos de botellas originales, limitantes estructurales}

El cuello de botella principal que presentaba este codigo era en la 
resoluci\'on del sistema, especificamente en el codigo que calculaba la matriz de Kohn-Sham.
En el GPU, esta funci\'on insumia el 95\% del tiempo total, que en sistemas grandes estaba
en el orden de minutos. Los problemas principales que mostraba esta funcion fueron:
\begin{itemize}
\item Cantidad de accesos a memoria global
\item Falta de accesos coalescentes
\item Sobreuso de la memoria compartida
\item Subsaturacion de los SM
\end{itemize}


\subsection{Cambios en el threading}
Cambiamos de blocks por funcion, a blocks por puntos
\subsection{Cambios en las memorias compartidas}
Accesos por bloque
\subsection{Cambios en los accesos globales}
La arquitectura de las placas de video estan pensadas entorno al poder de computo.
Las decisiones tomadas por los diseñadores de las GPGPU se concentran alrededor
de paralelismo a lo ancho, poniendo un gran enfasis en la cantidad de nucleos. Luego,
se dispone de menor cantidad de espacio disponible en el die para las memorias. 

Esta decision implica que la amplia mayoria de la memoria de la GPGPU se encuentra
localizada externa al procesador.  No solo esta fisicamente mas lejos, sino que
adem\'as la latencia para accederla es altisima. Es decir, el paradigma de
programaci\'on de las GPGPU gira entorno a esconder la gran latencia de los accesos
a las memorias globales.

Una de las memorias intermedias entre entre el procesador y la memoria global es
la memoria de textura. La memoria de textura es un cach\'e sobre la memoria global, 
que esta focalizado alrededor de los accesos a memoria en varias dimensiones.
Estas memorias reciben su nombre de su funcion principal, que es en el area de los
sistemas de video. Los mapas de textura suelen ser grandes matrices que definen
tanto los colores sobre las superficies de los poligonos como los relieves.
El detalle crucial de estas memorias es que un miss en estas cache, provoca
que se traigan datos no solo contiguos en memoria, como pasa en las caches de 
CPU normalmente, sino que ademas se traigan los datos en posiciones logicas contiguas,
es decir, variando las distintas dimensiones de la matriz subyacente. 

Las memorias de textura se ajustan bien a los problemas de GPGPU, porque se relacionan
intimamente con los los mecanismos de paralelismo de CUDA. Como los problemas se pueden
dividir en bloques con threads en $x$, $y$, $z$, entonces tiene mucho sentido pensar
que las estructuras de datos subyacentes se van a acceder usando indices multidimensionales.

En nuestro problema, la memoria de textura se presenta como una solucion para
los accesos bidimensionales de la matriz de RMM para el grupo de puntos. 
Como esta matriz debe ser multiplicada por todos los valores de las funciones,
derivadas primeras y segundas, se va a acceder a toda la matriz de RMM mas de
una vez por cada thread. Adem\'as, como se va a usar toda la matriz, y esta suele
tener un tamaño intermedio (es muy grande para memoria constante), el problema
suele entrar casi completamente en la memoria de textura.
La lectura bidimensional en este caso, se ajusta muy bien a los accesos por filas
y por columnas a la matriz.

El uso de la memoria de texturas agrega un recurso mas que tenemos que tener en
cuenta a la hora de profilear el codigo. Para administrar los accesos a 
la memoria de textura, cada multiprocesador tiene multiples "Unidades de textura".
Cuando dependemos de sobremanera de la memoria de textura para esconder la latencia,
se presentan contenciones sobre el acceso a las unidades de textura. Esto es
uno de los motivos por los cuales el procesador stallea los bloques hasta poder
ejecutarlos, cuando se liberan un poco mas los recursos.

\subsection{Cambios en la reduccion}
Hubo que agregar reduccion de suma a nivel punto porque ya no se comparten mas la info
\subsection{Cambios en los pasajes de informacion intrawarp}
Los shuffles que no anduvieron salvo en function
\subsection{Cambios en las operaciones matem\'aticas}
Cambiar los vec\_type4 por 3 en los accesos a la shared es mucho mejor, no hace falta alinear ahi
