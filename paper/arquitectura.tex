\subsection{Arquitectura y features GPGPU}

La arquitectura de las GPGPU esta enfocada a procesamiento de grandes cantidades de datos
de puntos flotante. El procesador de GPGPU cuenta con cientos de ALU sincronizadas
por bloques, permitiendo un paralelismo adaptativo a distintos problemas.

El procesamiento GPGPU es similar al procesamiento vectorial 
realizado por las supercomputadoras Cray y IBM que surgio en los 1960's.
El procesamiento consiste en en un hibrido entre compilador y procesador. Se determina
un conjunto de elementos a procesar y se elije una manera de dividirlos entre distintos
procesadores mediante distintas keywords del lenguaje. 

El paralelismo principalmente se divide en varios niveles:
\begin{enumerate}
  \item Thread Level
  \item Block Level
  \item Board level
\end{enumerate}

El paralelismo a nivel de thread permite comunicaciones internas las distintas ALU, pero
manteniendose dentro del mismo bloque de ejecucion.

El paralelismo a nivel de bloque permite agrupar una cantidad de threads de manera
que se procesen todos simultaneamente en el mismo procesador fisicamente, y que
cuando algunos de esos threads se bloquea por alguna razon, el bloque cesa de ejecutar
y es reemplazador por otro listo para ejecutar.

El paralelismo a nivel de placa consiste en poder distribuir la carga entre distintas
GPGPU dispuestas en un mismo sistema compartiendo una memoria RAM comun. 

La GPGPU cuenta a su vez con multiples clases de memorias que se adaptan de maneras
diferentes a los distintos procesos. Estas incluyen:

\begin{enumerate}
  \item Registros
  \item Memoria Global
  \item Memoria local
  \item Memoria Compartida
\end{enumerate}

Los registros son la unidad basica de almacenamiento de los kernels de ejecucion.
Cada thread de ejecucion cuenta con una cantidad limitada de registros de punto flotante de
acceso instantaneo. 

La memoria global es la memoria principal de la GPGPU. Esta es ilimitada en tama\~no 
y es compartida por todos los procesadores de la GPGPU y los CPU que integran el 
sistema. Es decir, tanto los GPGPU y los CPU pueden invocar las funciones de la libreria
para poder transferir datos de y hacia la memoria RAM.

La memoria compartida es una memoria que es visible para todos los threads dentro
de un bloque, pero es independiente entre bloques. Cada thread puede escribir en cualquier
parte de la memoria compartida de su bloque y puede ser leido por cualquier otro thread
de su bloque. Es una memoria muy rapida, que tarda una peque\~na cantidad de ciclos 
en poder ser leidos. Esta memoria es limitada y cuenta con una cantidad maxima del orden de los
Kb que debe ser compartido por todos los bloques.

La memoria local es un renombre de la memoria global, que es manejada por el compilador
de manera automatica y sirve para poder tener mas memoria interna al kernel de ejecucion
pero que sobrepase la cantidad de registros que cuenta ese thread para ejecutar.

La GPGPU cuenta con multiples niveles de memorias cache para poder aminorar el hecho
de que el principal cuello de botella del computo es la latencia en los accesos a memoria 
global.

\begin{enumerate}
  \item Cache L1
  \item Cache L2
  \item Cache de textura
\end{enumerate}

CacheL1??

La cache L2 es automatica. La seccion de la memoria que esta dedicada a la cache L2
tambien esta dedicada a la memoria compartida, por lo que es posible en tiempo de ejecucion
darle directivas a la GPGPU que prioritice una memoria sobre la otra, permitiendo 
mayor concurrencia o mayor hit rate de cache.

La cache de textura es una cache que presenta no solo localidad espacial, como la mayoria
de las caches de procesadores normales (i.e. dato-1, dato, dato+1, etc.), sino que se le
puede agregar el concepto de dimensiones, para poder modelar datos en mas de una dimension.
Esto la convierte en una herramienta clave a la hora de minimizar los accesos a matrices
no solo por filas sino por columnas. Esta memoria se debe definir en momento de compilacion,
en el codigo y no es automatica, porque esta cache tiene limites espaciales (necesarios
para poder definir areas de memoria sobre la cual operar) y a su vez se debe acceder
a los dayos subyacentes a traves de funciones especificas.

\subsection{Requerimientos de un problema para GPGPU}
En un principio, al ser GPGPU una arquitectura con completo poder expresivo, se puede
calcular cualquier cosa. Sin embargo, hay altos costos en los que se incurren antes de
poder ejecutar fragmentos de codigo. Un problema debe exhibir las siguientes caracteristicas
para que valga la pena poder pensar en correrlo para GPGPU.
\begin{enumerate}
  \item El problema debe tener una gran parte paralelizable.
  \item El problema debe consistir mayormente de operaciones numericas de punto flotante.
  \item El problema debe poder ser modelado mayormente en arreglos o matrices.
  \item El tiempo de computo debe ser muy superior al tiempo de transferencia de datos.
\end{enumerate}

Item \ref{req_paralelo} se refiere a que debe existir alguna forma de partir el problema
en subproblemas que puedan realizarse simultaneamente, sin que haya dependencias de 
resultados entre si. Si el problema requere partes seriales, lo ideal es que se las
pueda concebir las partes paralelas sean etapas de un pipeline de procesos, donde 
cada una de estas exhiba caracteristicas fuertemente paralelas.

Item \ref{req_float} habla de que el m\'etodo de resoluci\'on de los problemas debe
consistir del uso de metodos numericos. El set de instrucciones de las arquitecturas
de GPGPU estan fuertemente influenciados por las aplicaciones 3D que las impulsaron
en un principio. Estas consisten mayormente de transformaciones de algebra lineal
para modelar luces, hacer renders o mover puntos de vistas. Todos estos problemas
son inherentemente de punto flotante, por lo cual el set de instrucciones, las ALUs
internas y los registros tienen optimizado para este caso de uso. Las operaciones
en numeros enteros no son el fuerte de esta arquitectura y suelen ser realizados
mas eficientemente por procesadores de proposito general.

Item \ref{req_matrix} menciona que los problemas que mejor se pueden tratar en esta
arquitectura se pueden representar como operaciones entre arreglos o matrices de
dos, tres o cuatro dimensiones. Las estructuras de datos que no estan secuenciales
en memoria pueden incurrir en multiples accesos a esta para recorrerlas, y en las
arquitecturas GPGPU son estos los que generan el mayor cuello de botella. Ademas,
son dificiles de paralelizar en multiples subproblemas. Tener como parametros de 
entrada matrices o arreglos que se puedan partir facilmente incurre en minimos
overheads de computo y permite aprovechar mejor las caches y las herramientas de
prefetching que brinda la arquitectura.

Item \ref{req_transf} ataca uno de los puntos criticos de esta arquitectura. Para poder
operar con datos, se requiere que estos esten en la memoria de la placa, no la memoria
de proposito general de la computadora. Esto quiere decir, que se deben hacer copias
explicitas entre las memorias, ya que ambas tienen espacios de direcciones independentientes.
Esta copia se realiza a traves de buses que, a pesar de tener un enorme throughput de
datos, tambien tienen una gran latencia (orden de milisegundos). Por lo tanto, para minimizar
el tiempo de ejecucion de un programa usando las GPGPU, se debe considerar tambien el
tiempo de transferencia de datos a la hora de determinar si el beneficio de computar en
menor tiempo lo justifica. 

Estas caracteristicas limitan enormemente la clase de problemas que una GPGPU puede
afrontar, y suelen ser una buena heuristica para determinar de antemano si vale la pena
invertir el tiempo necesario de la implementacion y ajuste fino.

\subsection{Funcionamiento de un GPGPU}
El procesador se encarga de levantar codigo de la RAM, ponerlo en la I\$ de la GPGPU
y de poner a correr todos los bloques en cada procesador


\subsection{Diferencia entre CPU y GPU - Procesadores especulativos}
Viendo la historia de CPU, podemos hacer un recorrido de los problemas que los dise\~nadores de procesadores
fueron enfrentandose a lo largo del tiempo mirando los componentes que fueron apareciendo.

(insertar foto de die de nehalem)

Caches - Pipelines - Predictores - Mas cache - Mas controladores de memoria - Multiple issues

Lo importante ac\'a es observar el patron: "no desechar algo que podramos necesitar pronto", 
"intentar predecir el futuro de los condicionales", "intentar correr multiples instrucciones a la vez 
porque puede llegar a bloquear en alguna de ellas."

Todos estos problemas convierten al CPU en una maquina que gira alrededor de la especulacion, 
de los valores futuros que van a tener las ejecuciones, del probable reuso de datos.
Podemos observar entonces que las unidades que verdaderamente hacen la ejecucion de las operaciones,
las ALU, son muy pocas en comparacion con la cantidad de dispositivos de soporte que estan
sobre el die del CPU. 

\ref{http://www.nvidia.com/content/PDF/fermi_white_papers/P.Glaskowsky_NVIDIAFermi-TheFirstCompleteGPUComputingArchitecture.pdf}

En contraste, las arquitecturas GPGPU son verdaderas maquinas de computo masivo. Estan dise\~nadas para
resolver una y otra vez operaciones muy bien definidas (intrucciones de punto flotante en su mayoria).
Comparativamente con un CPU, las ALU de las GPU son bastante pobres y lentas. No funcionan a las mismas 
velocidades de clock y deben estar sincronizadas entre si. Pero la gran ventaja esta en la cantidad. 
Un CPU cuenta con unas pocas ALU por core, dependiendo de su algoritmo de scheduling interno 
(alrededor de 16 cores por die de x86 es el tope de linea ofrecido actualmente). Un GPU cuenta con miles de ALUs en total 
(m\'as de 3000 CUDA Cores en Tesla K20). 
En contraste, un GPU dispone de pocas unidades de soporte del procesamiento. No tiene pipelines especulativos, el tama\~no de las caches
estan a ordenes de magnitud de las de CPU, la latencia a las memorias principales de la GPU estan a 
decenas de clocks de distancia, etc. Basicamente durante del disen\~no de la arquitectura GPGPU
buscaron resolver el problema del computo masivo pensando en hacer m\'as cuentas a la vez y 
recalcular datos viejos de ser necesario. Esto es una marcada diferencia contra los CPU, que estan
pensado en rehacer el menor trabajo posible y intentar mantener todos los datos que pueda en 
las memorias caches gigantescas.
 
Como los CPU tienen que poder soportar cualquier aplicacion, no pueden avocarse de lleno a una sola
problematica. El hecho de no tener que dise\~nar un procesador de proposito general permitio un cambio radical
a la hora de pensar como concebir una arquitectura de gran throughput auxiliar al procesador, no reemplazandolo
sino mas bien adicionando poder de computo.

Las arquitecturas Fermi (y agregar AMD) han concebido el dise\~no de un procesador de alto desempe\~no. 
Su meta principal es poder soportar grandes cantidades de paralelismo, mediante el uso de procesadores
simetricos, pero tomando la fuerte restriccion de "no siempre tiene que andar bien". Es decir, ellos
mismos asumen que el codigo que van a correr esta bien adaptado a la arquitectura y no disponen
casi de mecanismos para dar optimizaciones post compilacion, o \"free lunch\". Relajar esta restricci\'on 
les permitio romper con el modelo de computo de CPU y definir nuevas estrategias de paralelismo, 
que no siempre se adaptan bien a todos los problemas, pero para un subconjunto de los desafios que se 
presentan en el area de HPC y de videojuegos han probado ser un cambio paradigmatico.

\subsection{Idoneidad para el problema}
El problema de QM/MM enfrentado en este trabajo cuenta con mutiples operaciones matematicas de gran
volumen de calculos. En particular, las operaciones matriciales son los cuellos de botella en este
problema. 
Para obtener los valores numericos de densidad buscados en los puntos, se deben obtener las derivadas primeras
y segundas, lo cual implica hacer multiples operaciones de multiplicacion matricial. Estas multiplicaciones
pueden ser paralelizadas por columnas y por filas. Estos problemas estan fuertemente estudiados como paralelizarlos
en la literatura, ya que lso problemas de algebra lineal los requieren constantemente. 
En nuestro caso, se requieren para un sistema cientas de estas multiplicaciones, algunas con matrices de mas de
$500^2$ elementos. Al consistir este proyecto un sistema de resolucion num\'erico de las f\'ormulas de QM/MM,
los problemas enfrentados eran casi en su totalidad de operaciones de punto flotante. Luego, dados las
caracteristicas de contar con un fuerte nivel de paralelismo en los cuellos de botella y de ser operaciones
mayormente de punto flotante, determinamos que el uso de las GPGPU era idoneo, en comparacion con arquitecturas
de proposito general con menos GFLOPS.

\subsection{Arquitectura y features Xeon Phi}

\input{arquitectura-xeon-phi}
