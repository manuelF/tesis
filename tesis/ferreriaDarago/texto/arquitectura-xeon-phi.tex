
\section{XeonPhi}

\subsection{Introducci\'on}

La arquitectura Xeon Phi es la culminaci\'on de un trabajo iniciado por Intel en 2004, previendo
la necesidad de paralelismo masivo para aplicaciones futuras. Saliendo al mercado al final de 2012,
con el prop\'osito de competir en computo intensivo con NVIDIA CUDA, ha ganado gran tracci\'on dentro
de HPC a pesar de ser joven. Por ejemplo, ha sido fuertemente utilizada en la supercomputadora Tianhe-2 
de la Universidad de Sun Yat-Sen en China, listada en Top 500 como la supercomputadora m\'as r\'apida del
mundo en Junio 2013, Noviembre 2013 y Junio 2014~\cite{Top500XeonPhiJune2013},~\cite{Top500XeonPhiNov2013},~\cite{Top500XeonPhiJune2014}. Los 16000 nodos de esta supercomputadora contienen, adem\'as de dos Ivy Bridge Xeon, 3 coprocesadores
XeonPhi, dando un total te\'orico de 54.9 petaflops.

\subsection{Dise\~no de los procesadores}

\subsubsection{Microarquitectura general} 

En la concepci\'on del Xeon Phi se tuvieron en cuenta diversos factores, entre los cuales
se incluye el consumo energ\'etico. Uno de los objetivos fue disminuir la relaci\'on de
poder de c\'omputo por watt de los procesadores de Xeon de la \'epoca, manteniendo la
arquitectura ISA x86. Si bien el consumo no se ve\'ia impactado por el set de instrucciones, 
si se busc\'o eliminar diversas partes del procesador:, intentando mantener 
caracter\'isticas que sirvieran al tipo de aplicaci\'on a la que se estaba 
apuntando (programas altamente paralelos a nivel de datos y tareas)~\cite{BookXeonPhi}.

La microarquitectura de este coprocesador se basa fuertemente en muchos procesadores sim\'etricos (SMP), al menos 50, lo
cual justifica su nombre MIC (\textit{Many Integrated Core}). El objetivo, adem\'as de proveer un dise\~no
capaz de escalar a las necesidades de aplicaciones fuertemente paralelas, es permitir que las mismas puedan
ser desarrolladas con herramientas lo m\'as similar posibles a las existentes: cada procesador esta basado
en el dise\~no del Intel Pentium, con una ISA (\textit{Instruction Set Architecture}) muy similar a la de este.
Los agregados a la arquitectura son soporte para direccionamiento a 64 bits y nuevas instrucciones de vectorizaci\'on.

Los procesadores tienen un \textit{clock rate} de 1.0 GHz aproximadamente, haciendolos bastante lentos frente
a otros procesadores de Intel. Por ejemplo, los procesadores de un Intel Xeon CPU E5-2620 tienen un \textit{clock rate}
de 2.10 GHz, aproximadamente el doble.

Un esquema de la arquitectura de cada procesador puede verse en la figura~\ref{fig:xeon_phi_core}. Cada uno de los cores
permite hasta 4 \textit{threads} simult\'aneos, con el prop\'osito de esconder la latencia de memoria y del despacho de
instrucciones vectoriales. Adicionalmente, el uso de dos \textit{pipes} permite que se ejecuten 2
instrucciones por ciclos de clock.  Algunas instrucciones, sin embargo, solo pueden ser despachadas en una de las dos:
por ejemplo las instrucciones de vectorizaci\'on solo pueden ser ejecutadas en la \textit{U-pipe}. Para esto se dispone
de una unidad de vectorizaci\'on (VPU, \textit{Vector Processing Unit}) con 32 registros SIMD (\textit{Single Instruction
Multiple Data}) de 512 bits, con lo cual cada core puede te\'oricamente realizar 16 operaciones sobre punto flotante de
32 bits al mismo tiempo. La latencia de estas instrucciones es de 4 ciclos de clock, sin embargo gracias a un pipeline
se puede obtener un \textit{throughput} de 1 instrucci\'on vectorial por ciclo.

\subsubsection{Pipeline}

El \textit{pipeline} de instrucciones tiene siete estad\'ios para las instrucciones escalares, y las
instrucciones vectoriales ocupan otras 7. Un esquema de las etapas puede verse en la figura~\ref{fig::xeon_phi_pipeline}.
El pipeline puede stallearse parcialmente si alguna de las partes sufre un stall, a diferencia de lo que ocurre en 
arquitecturas como Intel Xeon.

El pipeline tiene las fases usuales del ciclo \textit{fetch-decode-execute}), pero con algunas modificaciones.

El \textit{instruction fetch} esta dividido en dos fases para elegir el \textit{thread} por hardware a ejecutar:
\textit{Prethread picker function} (PPF) y \textit{Picker function} (PF). En la fase PPF se mueve la instrucci\'on
a uno de los 4 buffers de \textit{prefetch} que tiene cada procesador. Por cada thread hay adem\'as dos streams de
instrucciones. Si un stream es stalleado por el pipeline, se puede despachar del otro thread.

El estad\'io PF selecciona el thread a ejecutar, usando el buffer de prefetch. Cada buffer tiene espacio para dos
instrucciones (porque puede despacharse una instrucci\'on por la \textit{U-pipe} y otra por la \textit{V-pipe}). PF
funciona de manera \textit{round robin} en los buffers de prefetch. Recargar este buffer (por ejemplo cuando hay un
\textit{miss} de cache de instrucciones) toma aproximadamente 4 o 5 ciclos.

Una vez que una instrucci\'on ha sido elegida para decodificarse, pasa a los estad\'ios D0 y D1, a una velocidad de
decodificaci\'on de 2 instrucciones por ciclo de \textit{clock}. De ahi son enviadas a los dos pipes para ejecutarse.
Por \'ultimo se pasa al estad\'io de \textit{writeback} (WB). No necesariamente cuando una instrucci\'on llega a esta
fase ha terminado de ejecutarse, puesto que si la operaci\'on es vectorial reci\'en termina de ejecutarse en la unidad
vectorial 5 ciclos despu\'es.

Este pipeline corto (7 etapas frente a las 20 de la arquitectura Pentium 5 en la que se basa Xeon Phi) contribuye a que
los \textit{branch predictions} tenga menor latencia, y las instrucciones escalares tengan poca latencia~\cite{IntelXeonPhiWhitePaper}.

\subsection{Estructura de cache}

Adem\'as de la unidad de vectrizaci\'on y la unidad escalar, cada procesador cuenta con 32 Kb de cache L1 y 512 Kb de cache
L2 unificada para datos y c\'odigo. Estas caches son \textit{set associative} \textit{8-way} con una linea de cache de 64 bytes. La cache de datos es no bloqueante, de manera que un \textit{miss} de cache de un thread en un core, no se produce un \textit{flush} del pipeline en los dem\'as threads.

La cache L2 mantiene su coherencia mediante el uso de un directorio distribuido de \textit{tags}. Un esquema del mismo puede
verse en la figura~\ref{fig:xeon_phi_arch_global}.

\subsection{Instruction Set Architecture}

\subsection{Organizaci\'on de la memoria}

\subsection{Conexion Host - Board}
\subsection{Modos de ejecuci\'on}
\subsection{Consumo}
\subsection{Herramientas de desarrollo y profiling}
\subsection{Idoneidad para la tarea}

\subsection{Hardware}

La arquitectura del Xeon Phi, parte de la linea de Intel Many Core Architecture (MIC), est\'a esquematizada
en la figura~\ref{fig:xeon_phi_arch}. Cada procesador esta esquematizado en~\ref{fig:xeon_phi_core}

La base de esta arquitectura consiste entre 60 y 80 cores SMP (\textit{Symmetric Multiprocessing}), con lo cual todos
ellos comparten la misma memoria principal. Cada uno de los cores tiene un \textit{clock rate} de 1 GHz,
con una arquitectura similar al set de instrucciones de Intel IA-32. Las principales diferencias con este
conjunto de instrucciones son el soporte para direccionamiento a 64 bits y nuevas instrucciones de vectorizaci\'on.

Cada procesador tiene adem\'as soporte para 4 \textit{threads}, es decir, 4 hilos de ejecuci\'on diferentes. Adicionalmente,
cada \textit{thread} puede ejecutar dos instrucciones por ciclo de clock, mediante el uso de dos pipes: \textit{V-pipe} y \textit{U-pipe}.
Algunas instrucciones, sin embargo, solo puede ser ejecutadas en una de las dos: por ejemplo las instrucciones de vectorizaci\'on solo pueden
ser ejecutadas en la \textit{U-pipe}. Para ejecutar estas instrucciones se dispone de una unidad de vectorizaci\'on (VPU, \textit{Vector Processing Unit}).
Esta unidad cuenta 32 registros SIMD (Single Instruction Multiple Data) de 512 bits. La latencia de estas instrucciones es de 4 ciclos de clock pero permiten
operar sobre 16 valores de punto flotante de precisi\'on simple (\textit{float}) a la vez.

Adem\'as de la unidad de vectorizaci\'on y la unidad escalar, cada procesador cuenta con 32 Kb de cache L1 y 512 Kb de cache
L2. Estas caches son asociativas \textit{8-way} y su linea de cache tiene 64 bytes. La coherencia de cach\'e se mantiene
mediante un directorio distribuido de \textit{tags} (v\'ease figura~\ref{fig:xeon_phi_arch}) dividido en 64 secciones e implementado
por hardware. La memoria principal consiste de memoria RAM GDDR5 en la placa, de 8 GB con velocidad de transferencia de 5.5 GT/s en 16 canales y con transferencia de 4
bytes. Esto nos da un l\'imite de ancho de banda te\'orico de 352 GB/s pero detalles de implementaci\'on de los chips limitan este valor a 200 GB/s.

Cada procesador, puede realizar pedidos de memoria independientes sin que la memoria se convierta en un cuello
de botella importante~\cite{Fang}. Sin embargo, los 4 \textit{threads} dentro de un \textit{core} ven sus accesos a memoria serializados.

Adicionalmente los cores est\'an conectados por dos anillos bidireccionales que les permite comunicarse entre si. La velocidad de
comunicaci\'on es suficiente para considerar que todos los procesadores son sim\'etricos (es decir, cada procesador puede comunicarse con
cualquier otro con un \textit{overhead} despreciable)~\cite{Fang}.

Por \'ultimo, cada procesador tiene un \textit{in-order pipeline} de corta longitud, diferencia importante con los cores de un procesador
estandar de la arquitectura x86. El \textit{pipeline} corto implica que las operaciones escalares no tienen latencia y las vectoriales tienen baja latencia,
y el costo por \textit{branch misprediction} es bajo~\cite{IntelXeonPhiWhitePaper}. Este punto diferencia fuertemente al Xeon Phi de aceleradores de computo como las GPGPU,
que tienen alto costo en las bifuraciones de decisiones. Sin embargo, el Xeon Phi no ejecuta instrucciones de manera \textit{out-of-order}, lo cual implica que muchas
t\'ecnicas de optimizaci\'on que explotan el paralelismo a nivel instrucci\'on usuales en arquitecturas como x86-64 no son aplicables.

La otra diferencia es nuevas instrucciones de vectorizaci\'on, incompatibles con sets de vectorizaci\'on anteriores de Intel (por ejemplo AVX o SSE 4.1).
Estas operaciones incluyen implementaciones por \textit{hardware} de operaciones com\'unes en HPC: rec\'iproco de un valor, ra\'iz cuadrada, potencia y
exponenciaci\'on, y operaciones m\'as relacionadas con la memoria como por ejemplo \textit{scatter and gatter} y stores \textit{streameados} de manera de aprovechar
mejor el ancho de banda que tiene la arquitectura.

El Xeon Phi es un coprocesador, lo cual implica que necesita ser instalado sobre una computadora que sirva de \textit{host}. La comunicaci\'on con este host
ocurre a trav\'es de un bus PCI Express, no comparten ni memoria ni otros perif\'ericos como por ejemplo disco duro. Existen dos m\'etodos para acceder al Xeon~\cite{BookXeonPhi}

\begin{enumerate}
    \item Nativo: El Xeon Phi permite correr c\'odigo directamente, mediante el uso de SSH (Secure SHell). Esto es gracias a la presencia de BusyBox Linux como sistema operativo,
    lo cual da soporte de sistema de archivos y entorno de ejecuci\'on. La interfaz utiliza TCP/IP virtualizado mediante el bus PCI Express. Si bien el coprocesador no tiene acceso a \textit{storage} persistente (puesto que el sistema operativo esta montado sobre la memoria) esto puede resolverse utilizando un sistema de archivos remoto montado en la memoria del host.
    \item Offloading: El \textit{host} puede delegar la ejecuci\'on de ciertas porciones de c\'odigo al coprocesador. Esto requiere que los datos necesarios para el c\'omputo sean copiados del \textit{host} al Xeon Phi, lo cual puede implicar que el bus puede ser un cuello de botella importante (puesto que los datos de entrada, y la salida deben ser movido al Xeon Phi y traidos de vuelta al finalizar el c\'omputo).
    \item Sim√©trico: En este modo de ejecuci\'on se piensa al Xeon Phi y su host como dos nodos en un \textit{cluster} de c\'omputo, y al bus PCIe como una red de alta velocidad.
Este modo es especialmente interesante si se dispone de m\'as de un Xeon Phi en un mismo host, y se utiliza una interfaz de pasado de mensajes entre ellos como por ejemplo MPI (\textit{Message Passing Interface}).
\end{enumerate}

Por \'ultimo, en pos de simplificar el trabajo de adaptar una aplicaci\'on a usar el Xeon Phi, el mismo provee una unidad de monitoreo de \textit{performance} (\textit{Performance
Monitoring Tool}, PMU). Esta unidad permite la colecci\'on de informaci\'on del coprocesador, aunque no tiene soporte para ciertas caracter\'isticas com\'unes a los procesadores
de lineas m\'as est\'andar de Intel (por ejemplo: \textit{sampling} preciso de eventos por \textit{hardware}, como por ejemplo ciclos por instrucci\'on o \textit{misses} de cache).



