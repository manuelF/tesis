\section{Aceleraciones alcanzadas en CUDA}
\label{resultados-cuda}

Despues de haber trabajado en las distintas optimizaciones, comparemos las mediciones
de tiempo definitivas alcanzadas en las mismas.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\plotwidth]{plots/cuda/final.png}
   \caption{Aceleraci\'on en veces del c\'alculo de XC de correr Hemoglobina comparando implementaci\'on original en CUDA contra
   las versiones optimizadas finales.}
   \label{plt:cuda-final}
\end{figure}

Podemos ver que las aceleracion

\section{Aceleraciones alcanzadas en CPU}

\section{Performance contra Xeon Phi}

\section{?`Qu\'e me conviene comprar?}
Luego de todas las mejoras realizadas a la aplicaci\'on LIO, queda la interrogante pendiente. Para
correr simulaciones de QM, ?`Qu\'e versi\'on me conviene correr, CPU o GPU?

Esta pregunta es siempre capciosa y es susceptible a cambios tecnol\'ogicos muy r\'apidamente. Intentaremos
responderla utilizando dos \textit{tiers} donde correr LIO, uno para una estaci\'on de trabajo
y el otro para un servidor de c\'omputo. Definimos, para cada configuraci\'on, una versi\'on para GPU y otra
para CPU de modo de priorizar los recursos invertidos. Se busc\'o que los costos de ambos niveles
sean parejos, de modo de hacer la comparaci\'on realista de que conviene invertir.

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Configuraci\'on& Estaci\'on de trabajo                                                                                                      & Servidor                                                                                              \\ \midrule
GPU                      & \begin{tabular} [c]{@{}l@{}} Intel Core i5-4460 @ 3.2GHz\\ 8GB RAM DDR3\\ 1 o 2 x GeForce GTX 780 3GB\end{tabular} & \begin{tabular}[c]{@{}l@{}}E3 low end\\ 16GB RAM DDR3\\ 1 o 2 x NVIDIA Tesla K40 12GB\end{tabular} \\ \hline \\
CPU                      & \begin{tabular}[c]{@{}l@{}}Intel Core i7-3770 CPU @ 3.40GHz \\ 16GB RAM DDR3\end{tabular}                     & \begin{tabular}[c]{@{}l@{}}2 x Intel Xeon E5-2620 v2 @ 2.10GHz\\ 32GB RAM\end{tabular}                             \\ \bottomrule
\end{tabular}
\label{tbl:configs}
\caption{Distintas configuraciones de estaciones de trabajo y servidores para computo de QM/MM usando LIO}
\end{table}

%en hemo k40
%total iter = 1s 331302
%iteration = 522937
%TODO especificar bien en algo medible.

Lo que primero se debe notar en GPU es que se usan placas que tienen potencia de c\'alculo casi equivalente
para las cuentas en simple precisi\'on. Sin embargo, elegimos una Tesla para configuraci\'on de servidor
porque son las placas mejor preparadas para HPC. Estas cuentan con cuatro veces mas memoria en la placa
que tiene ECC y con mayor MTFB (\textit{Mean Time Between Failures}), factor vital en servidores
que deben correr confiablemente.

La m\'etrica que usaremos para comparar los distintos sistemas es cuantas iteraciones del c\'alculo de
SCF se pueden ejecutar por d\'ia. Esto lo hacemos para medir estrictamente la performance
de QM, importante en simulaciones de \textit{Time-Dependant Density Functional Theory} por ejemplo, y no
hablar de las implementaciones de los sistemas de QM/MM que utilizan LIO.
Esta m\'etrica es similar a las que se usan en el \'area de MM. Programas como Amber\cite{Amber} la usan para comparar
distintas configuraciones de hardware sobre la cual correr mejor.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\plotwidth]{plots/otros/its-xc-dia.png}
    \caption{Cantidad de iteraciones de XC por d\'ia realizables usando distintas configuraciones corriendo Hemoglobina usando los
              par\'ametros \'optimos correspondientes despues de todas las optimizaciones. El (*) marca resultados teoricos extrapolando
              las aceleraciones alcanzadas en la secci\'on \ref{cuda-multiplaca}.}
    \label{fig:its-xc-dia}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=\plotwidth]{plots/otros/its-dia.png}
    \caption{Cantidad de iteraciones de SCF por d\'ia realizables usando distintas configuraciones corriendo Hemoglobina usando los
              par\'ametros \'optimos correspondientes despues de todas las optimizaciones. El (*) marca resultados teoricos extrapolando
              las aceleraciones alcanzadas en la secci\'on \ref{cuda-multiplaca}.}
    \label{fig:its-dia}
\end{figure}

Un factor a tomar en cuenta para analizar la performance de diversas configuraciones, como en la figura \ref{fig:its-dia},
es que el c\'alculo de SCF incluye contribuciones que no son solamente las relativas a intercambio correlaci\'on
(las estudiadas en esta tesis), por los cuales los tiempos de ejecuci\'on totales van
a presentar menores aceleraciones que las presentadas anteriormente. La cantidad de iteraciones de XC se ven
exclusivamente en la figura \ref{fig:its-xc-dia}. Mostramos de manera independiente el calculo de XC porque
creemos que es posible conseguir mejoras similares en el resto de las contribuciones de SCF.

La principal ventaja que se obtiene de correr en las estaciones de trabajo con GPU es la potencia
de c\'alculo concentrado en los dispositivos GPU. La mayor aceleraci\'on del calculo de XC se obtiene
usando dos GeForce GTX 780, en comparaci\'on con unicamente usando el procesador. Esto se condice con las hip\'otesis discutidas
anteriormente sobre que los n\'ucleos del procesador se encuentran completamente ocupados.
En cambio, las estaciones de trabajo con CPU cuentan con la ventaja de que se acelera tambi\'en el
resto de las operaciones que componen una iteraci\'on de SCF. Estos c\'alculos son de menor costo computacional
comparada con las de XC, pero luego de las aceleraciones alcanzadas por este trabajo, el peso de estas
es comparativamente grande. Como estas otras contribuciones de SCF no est\'an
aceleradas con GPU, ese recurso se subutiliza fuera de XC.

Cuando se comparan las configuraciones de servidores, el panorama cambia sustancialmente.
Las aceleraciones obtenidas en la versi\'on GPU provienen principalmente de un solo factor,
la mayor cantidad de memoria en la GPU. Esta memoria permite entonces mantener las matrices
de funciones en memoria sin tener que recalcularlas. Esta optimizaci\'on se detall\'o en la secci\'on
\ref{GuardarFunctionsGPU}. Como la GeForce GTX 780 cuenta con una velocidad de clock mayor a
la K40 (probablemente porque en la linea de placas para v\'ideo juegos sea m\'as importante
la performance que la estabilidad) las operaciones se realizan incluso mas r\'apido en la
versi\'on de consumidor. Sin embargo, la Tesla K40 tiene un costo alrededor de ocho veces mayor que la
GeForce GTX 780.

La configuraci\'on de CPU en cambio, la performance escala linealmente en la cantidad de cores.
Dadas las optimizaciones realizadas en CPU priorizando la escalabilidad, es de notar la gran
diferencia de performance con respecto a la configuraci\'on de estaci\'on de trabajo. Priorizar CPU
favorece tambi\'en a todo el resto del c\'alculo de SCF. Las as contribuciones que no son
de intercambio-correlaci\'on se resuelven, o bien a trav\'es de librer\'ias BLAS en CPU, o bien
aprovechando las t\'ecnicas de paralelizaci\'on autom\'atica que brindan los compiladores usados.

Comparando ambas configuraciones de servidores, hoy en d\'ia es mucho mas f\'acil encontrar
nodos de computo de HPC usando m\'ultiples procesadores que nodos con varias GPU por varios motivos.
Primero, porque son mas generales: los nodos se pueden usar para m\'ultiples aplicaciones de HPC,
todav\'ia mayormente basados en CPU. Segundo, motivos energ\'eticos: el consumo energ\'etico de un cluster
HPC es muy elevado y las GPU pueden tener altos consumos que hacen muy dif\'icil la disipaci\'on t\'ermica.
Finalmente, el costo: las placas GPU de la linea de servidores cuestan mas de seis veces que los
procesadores de muy alta gama que se usan en HPC. Si las aplicaciones no van a hacer uso constante
de estas y tener aceleraciones comparables con el costo, entonces puede incluso no ser rentables
para las aplicaciones .


