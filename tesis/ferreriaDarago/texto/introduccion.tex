Con la aparici\'on de las computadoras, han ganado espacio dentro de las ciencias naturales los m\'etodos de simulaci\'on.
El uso de estas t\'ecnicas permite validar modelos te\'oricos as\'i c\'omo tambien brindar informaci\'on detallada (microsc\'opica) del proceso simulado.

En el \'ambito de la qu\'imica existen diferentes modelos que permiten simular procesos de inter\'es.
Dentro de estos modelos hay dos que se destacan por su uso:
\begin{itemize}
\item Los m\'etodos basados en la mec\'anica cu\'antica, que proporcionan una descripci\'on de la estructura electr\'onica del sistema.

\item Los m\'etodos basados en la mec\'anica molecular, donde las mol\'eculas son tratadas mediante un campo de fuerza cl\'asico y los electrones no son tenidos en cuenta expl\'icitamente.
\end{itemize}

\section{Modelos Cu\'anticos (QM)}

El comportamiento de las part\'iculas livianas (c\'omo el electr\'on) est\'a regido por las leyes de la mec\'anica cu\'antica.
Este marco te\'orico desarrollado a comienzos del siglo XX propone que las part\'iculas (c\'omo electrones y protones) pueden (y deben en algunos casos)
ser descriptas c\'omo ondas. As\'i, cualquier propiedad de un sistema esta determinado por una funci\'on llamada \emph{funci\'on de onda} ($\Psi$) que satisface la ecuaci\'on de Schr\"{o}dinger dependiente del tiempo:

\begin{equation}
    \label{schro_time_dep}
    -\hbar\frac{\partial \Psi}{\partial t} (\mathbf{r},t) = \frac{-\hbar^2}{2\mu}\nabla^2 \Psi(\mathbf{r},t) + V(\mathbf{r},t) \Psi(\mathbf{r},t)
\end{equation}
donde $\mathbf{r} = (r_1,\dots,r_n)$ es el vector de todas las posiciones de las part\'iculas del sistema,
$m$ es la masa de una part\'icula cualquiera, $V$ es un campo externo que afecta a las part\'iculas y
$\hbar$ es la constante de Planck divida por $2\pi$. 

Si el campo externo no depende del tiempo esta ecuaci\'on se puede simplificar a:

\begin{equation*}
    \hat{H} =  -\frac{\hbar^2}{m} \nabla^2 + \hat{V}
\end{equation*}
que se conoce como la ecuaci\'on de Schr\"{o}dinger \textit{independiente del tiempo}

\begin{equation}
    \label{schro_time_indep}
    \hat{H} \Psi(\mathbf{r}) = E \Psi(\mathbf{r})
\end{equation}
donde $E$ es la energ\'ia asociada a la funci\'on de onda $\Psi$.

Ahora, si bien resolver esta ecuaci\'on diferencial ser\'ia suficiente para determinar todas las propiedades del sistema, esto no puede hacerse de
manera exacta cuando hay m\'as de un electr\'on en el mismo. Por este motivo, para problemas de mayor tama\~no se utilizan aproximaciones
para obtener una soluci\'on de la ecuaci\'on~\ref{schro_time_indep}.

Existen diversos m\'etodos para resolver de forma aproximada esta ecuaci\'on con diferente costo computacional y calidad de la respuesta obtenida. 
Dentro de estos m\'etodos hay uno que destaca por su excelente relaci\'on costo/calidad, el m\'etodo basado en la Teor\'ia de los Funcionales de la Densidad (DFT, Density Functional Theory) desarrollada por Hohenberg y Kohn en 1964.

En este marco te\'orico, la \textit{densidad electr\'onica} $\rho$ representa la probabilidad de encontrar un electr\'on en el espacio dada una configuraci\'on del sistema y ocupa un rol destacado.
La base de este m\'etodo consiste en dos teoremas publicados por Hohenberg y Kohn ~\cite{HohenbergKohn}.
Estos autores demuestran que $\rho$ y $V$ (y por lo tanto $\psi$) se encuentran relacionadas biunivocamente,
es decir que una dada densidad electr\'onica contiene la misma informaci\'on que la funci\'on de onda.
De esta manera cualquier observable (c\'omo la energ\'ia) puede ser representado c\'omo un funcional de la densidad (de all\'i su nombre).

Adem\'as propusieron la dependencia de la energ\'ia del sistema c\'omo funcional de la densidad de la siguiente forma:
\begin{equation}
    \label{hohenberg_kohn_energy}
    E[\rho] = T_s[\rho] + V_{ne}[\rho] + \frac{1}{2} \int \int \frac{\rho(\vec{r}_1) \rho(\vec{r}_2)}{r_{12}} d\vec{r}_1 d\vec{r_2} + E_{xc}[\rho]
\end{equation}

Donde $T_s[\rho]$ es la energ\'ia cin\'etica asociada con la densidad, $V_{ne}[\rho]$ es la energ\'ia potencial producto de la interacci\'on entre los
electrones (la densidad) y los n\'ucleos, el tercer t\'ermino es el resultado de la repulsi\'on de Coulomb entre electrones y $E_{xc}[\rho]$ es la
energ\'ia de intercambio y correlaci\'on. Este \'ultimo t\'ermino da cuenta de la energ\'ia asociada a escribir la funci\'on de onda de manera que cumpla con el principio de antisimetr\'ia de Pauli y de la correlaci\'on
en la posici\'on instant\'anea de los electrones.

Esta formulaci\'on es exacta si se conociera el t\'ermino $E_{xc}[\rho]$ dado que los dem\'as tienen soluci\'on anal\'itica. En las aproximaciones hechas para calcular el mismo reside tanto la calidad c\'omo el costo
computacional de este tipo de simulaciones. Por ello, el objetivo central de este trabajo consiste en mejorar el tiempo insumido en el computo de este t\'ermino.

La forma comunmente utilizada para calcular este t\'ermino se basa en definir un funcional local $\epsilon_{xc}$ que depende de la densidad (Local Density Aproximation, LDA) o de la densidad y su gradiente
(General Gardient Aproximation, GGA) en cada punto del espacio.

De esta manera se puede calcular $E_{XC}$ \todo{>Si es el mismo t\'ermino mencionado en \ref{hohenberg_kohn_energy} deber\'ia escribirse igual (min\'uscula en xc)} mediante la integral:

\begin{equation}
    E_{XC} = \int \rho(r) \epsilon_{xc}\left( \rho(r) \right ) dr
\end{equation}
\todo{>La integral no deber\'ia definirse sobre un dominio?}

Esta ecuaci\'on puede ser aproximada mediante una suma utilizando una grilla de puntos seg\'un:

\begin{equation}
    \label{approx_excenergy}
    E_{XC} \approx \sum_j \rho(r_j) \epsilon_{xc} (\rho(r_j))
\end{equation}

Otro aspecto importante de esta teor\'ia es que provee una manera de calcular la densidad $\rho$, mediante el denominado m\'etodo de Kohn-Sham~\cite{KohnSham}. 
Este m\'etodo se basa en el segundo teorema de Hohenberg y Khon, que establece que la densidad electr\'onica es la funci\'on que cumple que $\int \rho(r) dr = N$, la cantidad de \'atomos del sistema, $\rho(r) \geq 0$ y que minimiza la energ\'ia $E[\rho]$~\ref{hohenberg_kohn_energy}. 
Esto produce un m\'etodo auto-consistente para calcular $\rho$. Se empieza con una aproximaci\'on inicial y se itera el c\'alculo de la misma usando una matriz, denominada \textit{Matriz de Kohn Sham}, hasta alcanzar un m\'inimo para $E$.

El algoritmo que se deduce de la DFT es uno de los m\'etodos m\'as populares en problemas de estado s\'olido, especialmente desde la d\'ecada del 90 cuando se mejoraron las aproximaciones para modelado de interacciones. 
El valor de esta teor\'ia para el estudio de las propiedades de la materia le vali\'o a Kohn el Premio Nobel de Qu\'imica en 1998.

Si bien la relaci\'on costo calidad de este m\'etodo es muy buena, el costo computacional asociado sigue siendo elevado, lo que limita su aplicaci\'on a sistemas peque\~nos (digamos cientos de \'atomos como m\'aximo).

Por ello se han desarrollado los m\'etodos conocidos como \emph{mec\'anica molecular} (MM). 
En estos m\'etodos los \'atomos son tratados c\'omo esferas cargadas y las uniones qu\'imicas como resortes (potenciales arm\'onicos).
De esta manera los electrones no son considerados expl\'icitamente, reduciendo dr\'asticamente el costo computacional asociado. 
Esta t\'ecnica es muy poderosa para representar sistemas (o procesos) en los que no cambia la distribuci\'on electr\'onica.

Sin embargo, en muchos de los problemas de inter\'es en qu\'imica y bioqu\'imica (por ejemplo una reacci\'on qu\'imica en soluci\'on o en el seno de una prote\'ina), el modelado requiere simult\'aneamente de la representaci\'on de miles de \'atomos y de un tratamiento expl\'icito de los electrones.
Para resolver esto, se han desarrollado t\'ecnicas h\'ibridas QM/MM (\textit{Quantum Mechanical / Molecular Mechanics}).

Dentro de este esquema se subdivide el sistema en dos partes:
\begin{enumerate}[i)]
\item Una parte en la que la estructura electr\'onica cambia. Se lo modela usando mec\'anica cu\'antica (QM).

\item Para el resto del sistema se aplica un campo de fuerzas cl\'asico (MM).
\end{enumerate}

De esta manera se puede expresar la energ\'ia del sistema QM/MM c\'omo:
\begin{equation}
    E = E_{QM} + E_{QM/MM} + E_{MM}
\end{equation}
donde la energ\'ia $E_{QM}$ se obtiene mediante el m\'etodo DFT visto m\'as arriba, y la energ\'ia $E_{MM}$ proviene de simular el campo de fuerzas cl\'asico.

La contribuci\'on $E_{QM/MM}$ se calcula, en este trabajo, mediante la ecuaci\'on:

\begin{equation}
    E_{QM/MM} = \sum_{l = 1}^{N_c} q_l \int \frac{\rho(r)}{\mid r - R_l \mid} + \sum_{l = 1}^{N_c}\sum_{\alpha = 1}^{N_q} [ v_{LJ} ( \mid R_l - \tau_\alpha \mid ) + \frac{q_l z_\alpha}{\mid R_l - \tau_\alpha \mid} ]
\end{equation}
donde el primer t\'ermino relaciona una carga puntual del sistema cl\'asico con la densidad electr\'onica, y el segundo t\'ermino representa la interacci\'on entre los n\'ucleos cl\'asicos con los cu\'anticos mediante un potencial de Lennard-Jones y la interacci\'on Coulombica entre las cargas.

Los m\'etodos \textit{QM/MM}, dentro del marco de m\'etodos multiescala, son ampliamente utilizados en la pr\'actica. 
Estos modelos han valido a Karplus, Levitt y Warshel el premio Nobel de Qu\'imica en 2013, por su valor para la simulaci\'on de sistemas complejos.

Nuestro trabajo se realiza en base a programas ya existentes. 
El c\'alculo de $E_{QM}$ y $E_{QM/MM}$ son realizados por la aplicaci\'on LIO~\cite{Nitsche2014,TesisNitsche}, el cual fue optimizado en este trabajo para el uso de distintas arquitecturas de CPU y GPGPU. 
Este paquete se complementa mediante el uso del programa de din\'amica molecular Amber~\cite{Amber}, que realiza el c\'alculo de $E_{MM}$. 
Nos concentraremos en las partes computacionalmente m\'as intensivas de LIO, que corresponden a la implementaci\'on de los c\'alculos de los t\'erminos de intercambio y correlaci\'on ya introducidos en esta secci\'on.

\section{C\'omputo de alto rendimiento}

Una parte significativa del impacto de las computadoras en los distintos aspectos de las ciencias, incluso de la vida diaria, se debe al crecimiento de su poder de c\'omputo desde la aparici\'on de los primeros microprocesadores hasta los disponibles hoy en d\'ia.

Entre 1986 y 2002, la performance de los procesadores creci\'o, en promedio, un $50\%$ por a\~no~\cite{Pacheco2011}. 
La denominada \textit{Ley de Moore} establece que la densidad de transistores por circuito integrado se duplica cada $18$ meses~\cite{HennessyPatterson}.
Esto puede verse en la figura~\ref{moore-law}, que compara la cantidad de transistores de distintos procesadores desde 1971 a la actualidad.

Este crecimiento permiti\'o a los desarrolladores de procesadores incrementar la potencia de c\'alculo, duplicando la performance cada 24 meses.
Esto benefici\'o durante mucho tiempo a los desarrolladores de aplicaciones, quienes escrib\'ian programas secuenciales, que solo deb\'ian esperar a la aparici\'on de los nuevos modelos de procesadores para ver una reducci\'on sustancial en los tiempos de ejecuci\'on de sus aplicaciones (fen\'omeno denominado \textit{hardware free lunch}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\plotwidth]{images/moore-law.pdf}
   \caption{Cantidad de transistores en procesadores emblem\'aticos desde 1971}
   \label{moore-law}
\end{figure}

Sin embargo, a medida que los transistores disminuyen su tama\~no, aumentan su disipaci\'on t\'ermica por unidad de superficie.
Esto limita la cantidad que se pueden ubicar en un circuito sin producir que este se comporte de manera err\'atica.
El mismo motivo impide el crecimiento de frecuencia de reloj.

Los problemas t\'ermicos han implicado que desde el 2002, la tasa de crecimiento de la performance de los monoprocesadores haya disminuido a un 20\% anual.
Consecuentemente, los principales fabricantes de procesadores han modificado el enfoque de investigaci\'on y dise\~no, empezando a hacerse m\'as y m\'as com\'un el uso de m\'ultiples procesadores por chip.

La preocupaci\'on por la disipaci\'on y el consumo energ\'etico insustentables han sido motivadores de dise\~nos con menor frecuencia de clock, pero aprovechando las a\'un crecientes densidades de transistores para incrementar las unidades de soporte.
Esta estrategia ha resultado en que, en un CPU moderno, menos del 20\% de todos los transistores disponibles se utilicen para realizar c\'alculos.

Adicionalmente, las mejoras de performance debidas al paralelismo a nivel de instrucci\'on (mediante t\'ecnicas como ejecuci\'on fuera de orden, ejecuci\'on especulativa, \textit{pipelining}, etc.) han sido progresivamente menores.
Actualmente, los esfuerzos invertidos en ese \'area se han concentrado en el paralelismo a nivel de datos (vectorizaci\'on) y paralelismo a nivel de tareas (multiprocesadores)~\cite{HennessyPatterson}.

Este enfoque en dise\~no de arquitecturas hacia otros tipos de paralelismo puede verse tanto en nuevos productos en las l\'ineas establecidas (por ejemplo los procesadores Intel i3, i5 e i7) as\'i como tambi\'en en nuevos desarrollos que apunten a c\'omputo de alta performance.
La revalorizaci\'on de las placas gr\'aficas (GPUs) para problemas de c\'omputo intensivo, y los desarrollos nuevos como la arquitectura MIC (\textit{Many Integrated Core Architecture}) de Intel son claros ejemplos de esta tendencia.

El impacto de este enfoque hacia m\'ultiples hilos de ejecuci\'on en paralelo en el desarrollo de aplicaciones es significativo.
En simulaciones para las \'areas de biolog\'ia, medicina, qu\'imica o meteorolog\'ia es de invaluable utilidad minimizar los tiempos de ejecuci\'on, para permitir mejores implementaciones de los modelos utilizados, permitiendo realizar predicciones de mayor calidad.
Aprovechar las nuevas arquitecturas multiprocesador requiere modificaciones en el c\'odigo que resultan no triviales, a diferencia del crecimiento en velocidad de \textit{clock} que no requer\'ia modificaciones en el dise\~no del programa.
Los intentos de escribir programas que conviertan programas seriales (dise\~nados para un solo procesador) a paralelos, en lenguajes de prop\'osito general como C, C++ o Fortran, han sido relativamente infructuosos~\cite{Pacheco2011}.

Existen, sin embargo, herramientas que realizan transformaciones de c\'odigo fuente serial a c\'odigo fuente con anotaciones de paralelizaci\'on autom\'aticas (usando bibliotecas de paralelizaci\'on asistida como OpenMP para las anotaciones).
Ejemplos de estas herramientas incluyen Par4All~\cite{Par4AllThesis} y Cetus~\cite{CetusPaper}. 
Estas herramientas pretenden, adem\'as, generar c\'odigo para aceleradores especiales como GPGPUs.

Como consecuencia, resulta necesario el trabajo a nivel de desarrollo de c\'odigo para utilizar m\'ultiples procesadores.
La aparici\'on de nuevas herramientas ayudan al programador en la tarea del uso eficiente de los recursos computacionales existentes.
Un ejemplo de esto es \nvidia CUDA~(\textit{Compute Unified Device Architecture}), que provee una arquitectura y lenguaje de programaci\'on para el desarrollo de aplicaciones que exploten los recursos provistos por tarjetas gr\'aficas, constituyendo la metodolog\'ia conocida como GPGPU~(\textit{General Purpose Graphical Processing Units}).
Otros ejemplos los podemos ver en APIs y bibliotecas unificadas de desarrollo como OpenMP o MPI~(\textit{Message Passing Interface}), trabajando conjuntamente con compiladores
con alto desarrollo en optimizaci\'on como Intel ICC y PGI Fortran.

Estas herramientas, si bien resultan en una asistencia muy importante para el programador, no constituyen \textit{silver bullets}.
Todav\'ia la divisi\'on del trabajo es inherente al problema a resolver en base a las dependencias de las tareas involucradas.
Realizar esta divisi\'on es una labor que, hasta el d\'ia de hoy, es inherente al programador especializado.

En este trabajo, buscaremos comparar distintas arquitecturas de hardware y c\'omo las caracter\'isticas espec\'ificas de la simulaci\'on qu\'imica a realizar permiten o impiden la paralelizaci\'on de trabajo empleando los distintos recursos que cada arquitectura provee.
